lesson-6-3-learning-to-rank-part-3-optional
https://d18ky98rnyall9.cloudfront.net/CS-V-2014-7_29_LearningtoRank_Part_3_V2.23c2f9c0df6c11e4bad7993d232815a7/full/540p/index.webm?Expires=1637798400&Signature=IbReqaWlO72LTPhg80i1hj05wNhzmILp4JpnlaUH1XeoErkVbcsr6U6qdhawPezEcmxHeu8eSGnRn~SwftK6PKoMnJ2ikm~jnW4De2p8UC29xwIk0hqFIgRy~9e23GjBB5SffqbVWnJKrTbxJXSODAwy-3mdr5rlBTaT6ZcMXTg_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A
0:00 : [SOUND] There are many more of the Munster learning algorithms than the regression based approaches and they generally attempt to direct the optimizer retrieval method. 
0:16 : Like a MAP or nDCG. 
0:19 : Note that the optimization object or function that we have seen on the previous slide is not directly related to the retrieval measure. 
0:31 : By maximizing the prediction of one or zero, we don't necessarily optimize the ranking of those documents. One can imagine that our prediction may not be too bad. And let's say both are around 0.5. So it's kind of in the middle of zero and one for the two documents. But the ranking can be wrong, so we might have a larger value for E2 and then E1. 
1:00 : So that won't be good from retrieval perspective, even though function, it's not bad. In contrast, we might have another case where we predicted the values, or around the 0.9, it said. And by the objective function, the error would be larger. But if we didn't get the order of the two documents correct, that's actually a better result. So these new, more advanced approaches will try to correct that problem. Of course, then the challenge is that the optimization problem will be harder to solve. And then, researchers have posed many solutions to the problem, and you can read more of the references at the end, know more about these approaches. Now, these learning ranked approaches after the general. So there accounts would be be applied with many other ranking problems, not just the retrieval problem. So some people will go with recommender systems, computational advertising, or summarization and there are many others that you can probably encounter in your applications.. 
2:11 : To summarize this lecture we have talked about using machine learning to combine much more features including ranking results. 
2:22 : Actually the use of machine learning 
2:25 : in information retrieval has started since many decades ago. So for example, the Rocchio feedback approach that we talked about earlier was a machine learning approach prior to relevance feedback. But the most recent use of machine learning has been driven by some changes in the environment of applications of retrieval systems. 
2:52 : First, it's mostly freedom of availability of a lot of training data in the form of critical, such as they are more available than before. So the data can provide a lot of useful knowledge about relevance and machine learning methods can be applied into a leverage list. Secondly, it's also freedom by the need for combining many features, and this is not only just because there are more features available on the web that can be naturally used for improved scoring. It's also because by combining them, we can improve the robustness of ranking, so this is desired for combating spams. Modern search engines all use some kind of machine learning techniques to combine many features to optimize ranking and this is a major feature of these commercial engines such a Google or Bing. 
3:56 : The topic of learning to rank is still active research topic in the community, and so we can expect to see new results in development in the next few years, perhaps. 
4:12 : Here are some additional readings that can give you more information about how learning to rank at works and also some advanced methods. 
4:25 : [MUSIC] 
